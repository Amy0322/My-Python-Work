{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 10s 1us/step\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND = tensorflow\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import imdb\n",
    "#num_words=10000意思接受出現頻率等於10000次的字\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#提供的training data和testing data數量\n",
    "len(x_train)\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1230,\n",
       " 3765,\n",
       " 566,\n",
       " 97,\n",
       " 189,\n",
       " 102,\n",
       " 86,\n",
       " 7,\n",
       " 32,\n",
       " 4,\n",
       " 973,\n",
       " 16,\n",
       " 55,\n",
       " 355,\n",
       " 18,\n",
       " 14,\n",
       " 20,\n",
       " 4,\n",
       " 64,\n",
       " 542,\n",
       " 173,\n",
       " 16,\n",
       " 4,\n",
       " 893,\n",
       " 2115,\n",
       " 5376,\n",
       " 250,\n",
       " 39,\n",
       " 8013,\n",
       " 4,\n",
       " 1362,\n",
       " 2,\n",
       " 14,\n",
       " 102,\n",
       " 47,\n",
       " 57,\n",
       " 599,\n",
       " 633,\n",
       " 6,\n",
       " 1317,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 189,\n",
       " 20,\n",
       " 57,\n",
       " 206,\n",
       " 57,\n",
       " 116,\n",
       " 5,\n",
       " 57,\n",
       " 836,\n",
       " 82,\n",
       " 6,\n",
       " 1317,\n",
       " 2,\n",
       " 3728,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 52,\n",
       " 284,\n",
       " 21,\n",
       " 29,\n",
       " 9,\n",
       " 38,\n",
       " 2245,\n",
       " 5,\n",
       " 1044,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 45,\n",
       " 619,\n",
       " 50,\n",
       " 71,\n",
       " 6,\n",
       " 171,\n",
       " 531,\n",
       " 15,\n",
       " 71,\n",
       " 424,\n",
       " 8,\n",
       " 30,\n",
       " 163,\n",
       " 6211,\n",
       " 4,\n",
       " 1629,\n",
       " 189,\n",
       " 212,\n",
       " 102,\n",
       " 5,\n",
       " 57,\n",
       " 31,\n",
       " 1498,\n",
       " 11,\n",
       " 4,\n",
       " 311,\n",
       " 13,\n",
       " 197,\n",
       " 15,\n",
       " 14,\n",
       " 20,\n",
       " 16,\n",
       " 1150,\n",
       " 1479,\n",
       " 5,\n",
       " 13,\n",
       " 161,\n",
       " 990,\n",
       " 692,\n",
       " 5,\n",
       " 1706,\n",
       " 12,\n",
       " 69,\n",
       " 77,\n",
       " 1194,\n",
       " 8,\n",
       " 3245,\n",
       " 2001,\n",
       " 553,\n",
       " 67,\n",
       " 14,\n",
       " 20,\n",
       " 48,\n",
       " 25,\n",
       " 423,\n",
       " 13,\n",
       " 131,\n",
       " 124,\n",
       " 51,\n",
       " 25,\n",
       " 122,\n",
       " 236,\n",
       " 1506,\n",
       " 198,\n",
       " 4,\n",
       " 64,\n",
       " 552,\n",
       " 7,\n",
       " 415,\n",
       " 37,\n",
       " 62,\n",
       " 169,\n",
       " 14,\n",
       " 20,\n",
       " 60,\n",
       " 2602,\n",
       " 629,\n",
       " 5,\n",
       " 615,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 25,\n",
       " 1230,\n",
       " 3765,\n",
       " 570,\n",
       " 231,\n",
       " 189,\n",
       " 102,\n",
       " 14,\n",
       " 20,\n",
       " 166,\n",
       " 2039,\n",
       " 168,\n",
       " 40,\n",
       " 2450,\n",
       " 5486,\n",
       " 3298]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#輸入資料的樣子，每個數字代表一個字，1為第一常出現，以此類推\n",
    "x_train[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218,189,141,550,147,43,123,562,233,130,"
     ]
    }
   ],
   "source": [
    "#前十筆資料的長度(字數)\n",
    "for i in range(10):\n",
    "    print(len(x_train[i]),end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#輸出資料的樣子，0(負評)，1(正評)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#設輸入資料長度的上限，並把每段文字弄成一樣長，太短的後面補 0\n",
    "from keras.preprocessing import sequence\n",
    "x_train = sequence.pad_sequences(x_train,maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen=100)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建構RNN神經網路，將文字壓到比較小的維度，且這些向量又代表某些意思(如兩向量角度小表相關程度大)，這叫word embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding\n",
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#embedding層可以把離散或整數的資料變得連續，Embedding(原資料數,壓縮後數量)\n",
    "#可用LSTM或GRU(較快)訓練\n",
    "model.add(Embedding(10000,128))\n",
    "model.add(GRU(150))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 150)               125550    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 1,405,701\n",
      "Trainable params: 1,405,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#計算 3*(128上層傳來input+150鄰居傳來+1bias)*150個 + (128+150+1)*150 = 167400\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#組裝\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 104s 4ms/step - loss: 0.4189 - acc: 0.8021\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 102s 4ms/step - loss: 0.2448 - acc: 0.9040\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 142s 6ms/step - loss: 0.1561 - acc: 0.9423\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 134s 5ms/step - loss: 0.0962 - acc: 0.9671\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 130s 5ms/step - loss: 0.0597 - acc: 0.9794\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 125s 5ms/step - loss: 0.0412 - acc: 0.9870\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 98s 4ms/step - loss: 0.0249 - acc: 0.9920\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 155s 6ms/step - loss: 0.0183 - acc: 0.9942\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 110s 4ms/step - loss: 0.0154 - acc: 0.9946\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 125s 5ms/step - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 132s 5ms/step - loss: 0.0138 - acc: 0.9959\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 140s 6ms/step - loss: 0.0094 - acc: 0.9966\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 139s 6ms/step - loss: 0.0097 - acc: 0.9968\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 142s 6ms/step - loss: 0.0037 - acc: 0.9988\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 134s 5ms/step - loss: 0.0047 - acc: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b418c386d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#訓練\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 29s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#檢視成果\n",
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.18376077208519\n",
      "acc: 0.82892\n"
     ]
    }
   ],
   "source": [
    "#檢測資料的loss和檢測資料的正確率\n",
    "print('loss',score[0])\n",
    "print('acc:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1877"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將神經網路存起來\n",
    "model_json=model.to_json()\n",
    "open('imdb_model_architecyure.json','w').write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('indb_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#另一種存的方式\n",
    "model.save('myrnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
